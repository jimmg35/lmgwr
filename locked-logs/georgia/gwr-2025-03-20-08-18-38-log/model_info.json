{
 "model_type": "gwr",
 "bandwidth_optimization": [
  {
   "episode": 1,
   "reward": 299.9355867080565,
   "r2": 0.6853091633209034,
   "bandwidth": 101
  },
  {
   "episode": 4,
   "reward": 299.9355829799911,
   "r2": 0.6686140188133407,
   "bandwidth": 130
  },
  {
   "episode": 5,
   "reward": 299.9355867080565,
   "r2": 0.6853091633209034,
   "bandwidth": 101
  },
  {
   "episode": 6,
   "reward": 299.9355867080565,
   "r2": 0.6853091633209034,
   "bandwidth": 101
  },
  {
   "episode": 7,
   "reward": 299.9355867080565,
   "r2": 0.6853091633209034,
   "bandwidth": 101
  },
  {
   "episode": 8,
   "reward": 299.9355867080565,
   "r2": 0.6853091633209034,
   "bandwidth": 101
  },
  {
   "episode": 9,
   "reward": 299.9355867080565,
   "r2": 0.6853091633209034,
   "bandwidth": 101
  },
  {
   "episode": 10,
   "reward": 299.77617113047955,
   "r2": 0.6849345327361547,
   "bandwidth": 102
  },
  {
   "episode": 11,
   "reward": 299.9355867080565,
   "r2": 0.6853091633209034,
   "bandwidth": 101
  },
  {
   "episode": 12,
   "reward": 299.77617113047955,
   "r2": 0.6849345327361547,
   "bandwidth": 102
  },
  {
   "episode": 13,
   "reward": 299.9355867080565,
   "r2": 0.6853091633209034,
   "bandwidth": 101
  },
  {
   "episode": 14,
   "reward": 299.9355867080565,
   "r2": 0.6853091633209034,
   "bandwidth": 101
  },
  {
   "episode": 15,
   "reward": 299.23582132193565,
   "r2": 0.6809605295573128,
   "bandwidth": 110
  },
  {
   "episode": 17,
   "reward": 299.77617113047955,
   "r2": 0.6849345327361547,
   "bandwidth": 102
  },
  {
   "episode": 18,
   "reward": 299.9355867080565,
   "r2": 0.6853091633209034,
   "bandwidth": 101
  },
  {
   "episode": 19,
   "reward": 299.9355867080565,
   "r2": 0.6853091633209034,
   "bandwidth": 101
  },
  {
   "episode": 20,
   "reward": 299.9355867080565,
   "r2": 0.6853091633209034,
   "bandwidth": 101
  },
  {
   "episode": 21,
   "reward": 299.9355867080565,
   "r2": 0.6853091633209034,
   "bandwidth": 101
  },
  {
   "episode": 22,
   "reward": 299.9355829799911,
   "r2": 0.6686140188133407,
   "bandwidth": 130
  },
  {
   "episode": 24,
   "reward": 299.77617113047955,
   "r2": 0.6849345327361547,
   "bandwidth": 102
  },
  {
   "episode": 26,
   "reward": 299.9355867080565,
   "r2": 0.6853091633209034,
   "bandwidth": 101
  },
  {
   "episode": 27,
   "reward": 299.77617113047955,
   "r2": 0.6849345327361547,
   "bandwidth": 102
  },
  {
   "episode": 29,
   "reward": 299.9355867080565,
   "r2": 0.6853091633209034,
   "bandwidth": 101
  },
  {
   "episode": 30,
   "reward": 299.77617113047955,
   "r2": 0.6849345327361547,
   "bandwidth": 102
  },
  {
   "episode": 31,
   "reward": 299.9355867080565,
   "r2": 0.6853091633209034,
   "bandwidth": 101
  },
  {
   "episode": 32,
   "reward": 298.88347155882656,
   "r2": 0.6778139263029976,
   "bandwidth": 117
  },
  {
   "episode": 33,
   "reward": 299.9355867080565,
   "r2": 0.6853091633209034,
   "bandwidth": 101
  },
  {
   "episode": 34,
   "reward": 299.9355867080565,
   "r2": 0.6853091633209034,
   "bandwidth": 101
  },
  {
   "episode": 35,
   "reward": 299.3996668077742,
   "r2": 0.6826275043101485,
   "bandwidth": 107
  }
 ],
 "info": [
  {
   "2025-03-20 08:18:38": "SpatialDataset : Data schema matchs with the data."
  },
  {
   "2025-03-20 08:18:38": "SpatialDataset : Data points created."
  },
  {
   "2025-03-20 08:18:38": "GwrKernel : Kernel is initialized."
  },
  {
   "2025-03-20 08:18:38": "GWR : GWR model is initialized."
  },
  {
   "2025-03-20 08:18:38": "GwrOptimizerRL: GwrOptimizerRL environment is initialized."
  },
  {
   "2025-03-20 08:18:38": "GwrOptimizerRL: Using AICC as the reward."
  },
  {
   "2025-03-20 08:19:25": "Episode 2 truncated, took 1000 steps, remain 10000 steps, reward: -330.8009460423051, r2: 0.7629490710812805."
  },
  {
   "2025-03-20 08:19:54": "Episode 3 truncated, took 1000 steps, remain 10000 steps, reward: -302.6863986555617, r2: 0.6917384205495778."
  },
  {
   "2025-03-20 08:21:38": "Episode 16 truncated, took 1000 steps, remain 10000 steps, reward: -306.5858885147677, r2: 0.6419689473863945."
  },
  {
   "2025-03-20 08:22:29": "Episode 23 truncated, took 1000 steps, remain 10000 steps, reward: -309.6501243873657, r2: 0.6309418412295376."
  },
  {
   "2025-03-20 08:22:57": "Episode 25 truncated, took 1000 steps, remain 10000 steps, reward: -309.6501243873657, r2: 0.6309418412295376."
  },
  {
   "2025-03-20 08:24:08": "Episode 28 truncated, took 1000 steps, remain 10000 steps, reward: -309.6501243873657, r2: 0.6309418412295376."
  },
  {
   "2025-03-20 08:24:37": "PPO: PPO finished training."
  }
 ],
 "matrices": {
  "AIC": null,
  "AICc": null,
  "R-squared": null,
  "R-squared adjusted": null
 }
}