import torch
from torch.utils.data import Dataset, DataLoader
import torch
import torch.nn as nn
import torch.optim as optim
import pandas as pd


from src.dataset.spatial_dataset import SpatialDataset
from src.dataset.interfaces.spatial_dataset import IFieldInfo
from src.log.lgwr_logger import LgwrLogger


class SpatialDatasetTorch(Dataset):
    def __init__(self, X, y, distance_matrix):
        """
        X: torch.Tensor (n, p) - è‡ªè®Šæ•¸
        y: torch.Tensor (n, 1) - ç›®æ¨™è®Šæ•¸
        distance_matrix: torch.Tensor (n, n) - æ‰€æœ‰é»ä¹‹é–“çš„è·é›¢çŸ©é™£
        """
        self.X = X
        self.y = y
        self.distance_matrix = distance_matrix
        self.n = X.shape[0]

    def __len__(self):
        return self.n  # ç¸½å…±æœ‰ n å€‹é»

    def __getitem__(self, index):
        """
        å›å‚³ (distance_vector, X, y, index) ä½œç‚ºæ¨¡å‹çš„è¼¸å…¥
        """
        distance_vector = self.distance_matrix[index]  # å–å‡ºé» i çš„è·é›¢å‘é‡
        xi = self.X[index]  # å–å‡ºé» i çš„è‡ªè®Šæ•¸
        yi = self.y[index]  # å–å‡ºé» i çš„ç›®æ¨™è®Šæ•¸
        return distance_vector, xi, yi, index  # å¿…é ˆå›å‚³ index è®“æ¨¡å‹çŸ¥é“æ˜¯å“ªå€‹é»


class LGWR(nn.Module):
    """
    æ•´åˆ LBNNï¼ˆå­¸ç¿’ bandwidthï¼‰ã€ç©ºé–“åŠ æ¬Šè¨ˆç®—ã€GWR å›æ­¸çš„å®Œæ•´ LGWR æ¨¡å‹
    """

    def __init__(self, input_dim, X, y, min_bandwidth=1000, max_bandwidth=10000):
        super(LGWR, self).__init__()

        self.device = torch.device(
            "cuda" if torch.cuda.is_available() else "cpu")

        self.X = X
        self.y = y
        self.min_bandwidth = min_bandwidth
        self.max_bandwidth = max_bandwidth

        # LBNNï¼šå­¸ç¿’ bandwidth
        self.lbnn = nn.Sequential(
            nn.Linear(input_dim, 512),
            nn.ReLU(),
            nn.Linear(512, 256),
            nn.ReLU(),
            nn.Linear(256, 128),
            nn.ReLU(),
            nn.Linear(128, 64),
            nn.ReLU(),
            nn.Linear(64, 32),
            nn.ReLU(),
            nn.Linear(32, 16),
            nn.ReLU(),
            nn.Linear(16, 1),
            nn.ReLU(),
            nn.Softplus()
        )

    def forward(self, distance_vector, Xi, yi, index):
        """
        1. é æ¸¬ bandwidth
        2. è¨ˆç®—åŠ æ¬ŠçŸ©é™£ W
        3. ä¼°è¨ˆ y_hat
        4. indexç”¨æ–¼ç´€éŒ„bandwidth
        """
        # é æ¸¬ bandwidth (é¿å… in-place æ“ä½œ)
        bandwidth = self.lbnn(distance_vector)
        bandwidth_scoped = bandwidth + 200000

        # bandwidth_scoped = torch.clamp(
        #     bandwidth,
        #     min=self.min_bandwidth, max=self.max_bandwidth
        # )  # é™åˆ¶ç¯„åœ

        # if index == 0:
        #     print(
        #         f"{index} | bandwidth: {bandwidth_scoped.item()} | raw: {bandwidth.item()}")

        # è¨ˆç®—ç©ºé–“åŠ æ¬ŠçŸ©é™£
        W = self.calculate_weighted_matrix(distance_vector, bandwidth_scoped)

        # è¨ˆç®— y_hat
        y_hat = self.estimate_y_hat(W, index)
        # if index == 0:
        #     # print(distance_vector)
        #     print(
        #         f"index {index[0]} | y_hat: {y_hat.item()} | bandwidth_scoped: {bandwidth_scoped.item()} | bandwidth: {bandwidth.item()}")

        return y_hat

    def calculate_weighted_matrix(self, distance_vector, bandwidths):
        """
        è¨ˆç®—ç©ºé–“åŠ æ¬ŠçŸ©é™£ W (exponential)
        """
        weights = torch.exp(- (distance_vector ** 2) / (bandwidths ** 2))
        return weights

    def estimate_y_hat(self, W, index):
        """
        æ ¹æ“šåŠ æ¬ŠçŸ©é™£ W ä¼°ç®— y_hat
        """

        XTW = self.X.mT * W
        XTWX = XTW @ self.X
        XTWy = XTW @ self.y
        beta = torch.linalg.solve(XTWX, XTWy)

        # xT = (self.X * W.T).T
        # xtx = torch.matmul(xT, self.X)
        # xtx_inv_xt = torch.linalg.solve(xtx, xT)
        # beta_oldway = torch.matmul(xtx_inv_xt, self.y)

        # é æ¸¬ y_hat
        y_hat = torch.matmul(self.X[index], beta)  # (1, p) @ (p, 1) -> (n, 1)

        # if index == 0:
        #     print(y_hat)
        #     print(self.y[index])
        #     print("=========")
        # print(W.shape)
        # print(self.X[index].shape)
        # print(beta.shape)
        # print("=================")

        # if index == 0:
        #     print(f"index {index} | y_hat: {y_hat.item()}")

        return y_hat.reshape(-1, 1)


def train_lgwr(X, y, distance_matrix, epochs=100, lr=0.01, batch_size=1):
    """
    è¨“ç·´ LGWRï¼ŒåŒ…å« LBNNï¼ˆå­¸ç¿’ bandwidthï¼‰èˆ‡ GWRï¼ˆè¨ˆç®—åŠ æ¬Šå›æ­¸ï¼‰
    """
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

    dataset = SpatialDatasetTorch(X, y, distance_matrix)
    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False)

    model = LGWR(
        X.shape[0], X, y
    ).to(device)
    optimizer = optim.Adam(model.parameters(), lr=lr)
    loss_fn = nn.MSELoss()

    for epoch in range(epochs):
        train_loss = 0.0
        y_true_all = torch.empty_like(y)
        y_pred_all = torch.empty_like(y)

        for distance_vector, Xi, yi, index in dataloader:
            optimizer.zero_grad()

            distance_vector = distance_vector.to(device)
            Xi = Xi.to(device)
            yi = yi.to(device)

            yi_hat_batch = model(distance_vector, Xi, yi, index)
            # print(distance_vector.shape)
            # print(Xi.shape)
            # print(yi.shape)
            # print(yi_hat_batch.shape)
            # print("=========")
            # print(distance_vector)
            # print(Xi)
            # print(yi)
            # print(yi_hat_batch)
            # print("=========")

            loss = loss_fn(yi_hat_batch, yi)
            loss.backward(retain_graph=True)
            optimizer.step()
            train_loss += loss.item()

            # ğŸš€ å„²å­˜æ‰€æœ‰ batch çš„ y_true & y_predï¼Œç”¨æ–¼è¨ˆç®— RÂ²
            y_true_all[index] = yi.item()
            y_pred_all[index] = yi_hat_batch.item()

        ss_total = torch.sum((y_true_all - y_true_all.mean()) ** 2)  # ç¸½è®Šç•°
        ss_residual = torch.sum((y_true_all - y_pred_all) ** 2)  # æ®˜å·®è®Šç•°
        r2_score = 1 - (ss_residual / ss_total)

        print(f"Epoch {epoch+1}/{epochs} - Loss: {train_loss} - R2: {r2_score}")

        # print(y_true_all)

        # print(y_pred_all)

    return model


if __name__ == "__main__":

    # è®€å–æ•¸æ“š
    logger = LgwrLogger()
    synthetic_data = pd.read_csv(r'./data/GData_utm.csv')

    spatialDataset = SpatialDataset(
        synthetic_data,
        IFieldInfo(
            predictor_fields=['PctBach', 'PctEld', 'PctBlack'],  # X çš„æ¬„ä½
            response_field='PctPov',  # y çš„æ¬„ä½
            coordinate_x_field='X',  # X åº§æ¨™
            coordinate_y_field='Y'   # Y åº§æ¨™
        ),
        logger,
        isSpherical=False
    )

    # è½‰æ›ç‚º Torch Tensor
    X = spatialDataset.x_matrix_torch  # (n, p)
    y = spatialDataset.y_torch  # (n, 1)

    # è¨ˆç®—è·é›¢çŸ©é™£ (n, n)
    distance_matrix = torch.cdist(
        spatialDataset.coordinates_torch, spatialDataset.coordinates_torch, p=2)

    # è¨“ç·´æ¨¡å‹
    lgwr_model = train_lgwr(
        X, y, distance_matrix,
        epochs=50,  # è¨“ç·´ 50 å€‹ epochs
        lr=0.001,  # å­¸ç¿’ç‡
        batch_size=32  # æ¯æ¬¡æ›´æ–° 1 å€‹é»
    )
